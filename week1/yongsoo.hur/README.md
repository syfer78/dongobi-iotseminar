사물인터넷을 위한 머신러닝/딥러닝
=============
## What is Machine Learning?
>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, __if its performance at tasks in T, as measured by P, improves with experience E__.
> 
> by Tom Mitchell

* Task : 머신 러닝을 통하여 해결하려는 문제
* Experience : 머신 러닝의 입력값. 즉 학습 데이터를 의미.
* Performance : 머신 러닝의 결과. 즉 예측치, 분류값 등의 목적한 결과값.

## 학습 종류에 따른 분류
### 1.지도학습
* 특정한 입력(Data)에 대하여 올바른 정답(Label)이 존재하는 경우의 학습
  
### 2.비지도학습
* 특정한 입력(Data)에 대하여 올바른 정답(Label)이 존재하지 않는 경우의 학습
  
### 3.강화학습
* 현재의 상태(State)에서 최적의 행동(Action)을 선택하는 방법을 학습

## 머신 러닝 알고리즘 소개
### 1. 예측
  * 선형회귀
    * 종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 회귀분석 기법
### 2. 분류
  * 로지스틱 회귀
    * 가중치 W와 편향치 b를 찾아서 입력된 특징 공간의 각 입력벡터 X <sub>i</sub>가 해당 계급 y<sub>i</sub> 로 정확히 분류되도록 함
      
  * 서포트 벡터 머신 (SVM)
    * 계급간의 margin이 최대가 되게 하는 최적 hyper-space를 찾아 분류
    * 입력 공간 특징이 선형이 아닐 경우 커널 함수를 도입하여 선형으로 변환
  * 나이브 베이즈
    * 베이즈 정리에 따른 빈도 기반 확률을 이용하여 분류
  * 결정트리
    * 스무고개
  * 앙상블 학습
    * 훈련 데이터를 이용하여 각기 다른 모델들을 학습시키고 분류기의 예측을 모은 뒤 최대 득표를 받은 계급을 선택.
    * 데이터셋을 구성하기 위해 bagging과 pasting을 사용할 수 있다.
### 3. 딥 러닝
  * 단순 퍼셉트론(Simple Perceptron)
    * 단일 뉴런을 사용한 모형
  * 다층 퍼셉트론(Multi Layer Perceptron)
    * 단일 뉴런을 여러 계층으로 쌓아서 다층으로 구성
    * 입력층 -> 은닉층 -> 출력층으로 구분되는 구조
    
  * 합성곱 신경망(CNN)
    * 합성곱 계층, 병합 계층, 완전 연결 계층으로 이루어진 신경망
    * 합성곱 계층
      * 데이터의 특징을 추출하는 계층. 데이터의 인접 성분을 조사해서 특징을 도출.
      * 일종의 압축으로 특징을 강화하는 과정
    * 병합계층
      * 합성곱을 거친 데이터의 사이즈를 줄이고 미세한 부분의 일관적인 특징을 도출
    * 완결 연결 계층
      * 일반적인 다층 퍼셉트론으로 이루어진 학습망
  * 재귀 신경망(RNN)
    * 반복적이고 순차적인 데이터 학습에 특화
    * 과거의 학습 결과를 가중치를 통해 현재 학습에 반영
    * 경사도 소실 문제가 발생할 수 있음 -> LSTM으로 진화
    * Long-Short Term Memory
      * RNN의 은닉층을 LSTM 셀로 대체
      * LSTM 셀은 망각 게이트, 입력게이트, 출력게이트로 구성
        * 망각 게이트 : 현재 시간대에서 추후 흐름을 위해 기억될 단기 기억인 h의 양 제어
        * 입력 게이트 : 입력 기억량과 작업 기억량을 제어
        * 출력 게이트 : 단기 기억을 갱신하는 데 사용되는 정보량을 제어
    * 게이트 처리 재귀장치(GRU)
      * LSTM보다 단순한 구조
      * 갱신게이트와 재설정 게이트로 구성되어있음
      * 바로 이전의 기억과 현재 입력 두가지만을 입력으로 받음
      * LSTM보다 훈련 파라미터가 적음
  * 오토 인코더
    * 비지도 학습으로 학습
    * 학습 파라미터가 적어도 빠르게 망이 학습할 수 있도록 한 구조.
  

